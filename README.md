# üö®üö™üèÉüèª‚Äç‚ôÇÔ∏è Detecci√≥n de evasi√≥n por puerta de vag√≥n en sistemas BRT

Este repositorio presenta un **m√©todo basado en visi√≥n por computador para la detecci√≥n autom√°tica de evasi√≥n de pago en puertas laterales de vagones en sistemas BRT**, desarrollado y validado utilizando videos reales del sistema TransMilenio en Bogot√°, Colombia.

El proyecto propone una soluci√≥n integral que combina **modelos de deep learning para percepci√≥n visual** con **an√°lisis de trayectorias y reglas espaciales**, permitiendo identificar ingresos ilegales en un escenario altamente complejo debido a la congesti√≥n, oclusiones y comportamientos humanos no estructurados.

---

## üéØ Contexto del problema

La evasi√≥n del pago del pasaje representa un problema operativo y econ√≥mico significativo en los sistemas de transporte masivo tipo BRT. En TransMilenio, una proporci√≥n considerable de usuarios ingresa al sistema de manera ilegal, particularmente a trav√©s de las puertas laterales de los vagones, donde el control es limitado.

Las metodolog√≠as tradicionales para medir este fen√≥meno dependen en gran medida de conteos manuales o de sistemas propietarios cuyos detalles t√©cnicos no son p√∫blicos, lo que dificulta su an√°lisis, comparaci√≥n y mejora.

<img width="1137" height="524" alt="image" src="https://github.com/user-attachments/assets/25c92c50-aa8c-4c77-86c8-c4f9c8079a9a" />

Este trabajo aborda la problematica desde un enfoque acad√©mico.

---

## üß† M√©todo propuesto

El m√©todo desarrollado fue probado con clips de video de corta duraci√≥n (20‚Äì24 segundos) y videos completos de hasta 20 minutos capturados por c√°maras fijas ubicadas en las estaciones, con vista hacia las puertas de los vagones. A diferencia de enfoques basados exclusivamente en reconocimiento de acciones o poses, esta propuesta se centra en el **an√°lisis espacio-temporal de las trayectorias de las personas en relaci√≥n con la geometr√≠a de la estaci√≥n**.

### Flujo general del m√©todo

1. **Segmentaci√≥n de la estaci√≥n**
   Se utiliza un modelo YOLO entrenado para segmentaci√≥n de instancias con el fin de detectar el pol√≠gono que define la estaci√≥n. Se consideran dos variantes del pol√≠gono (con y sin plataforma) para adaptarse a diferentes configuraciones y reducir falsos positivos.

2. **Detecci√≥n de personas**
   Las personas son detectadas cuadro a cuadro mediante modelos YOLO preentrenados y ajustados al contexto del problema. √önicamente se considera la clase *persona*.

3. **Seguimiento de personas (tracking)**
   A partir de las detecciones, se asignan identificadores √∫nicos a cada individuo utilizando algoritmos de tracking-by-detection como **ByteTrack** y **BoT-SORT**, permitiendo reconstruir trayectorias completas a lo largo del video.

4. **An√°lisis de trayectorias y reglas de decisi√≥n**
   En lugar de emplear reconocimiento expl√≠cito de poses debido a la poca resoluci√≥n de muchos casos, el m√©todo aplica un conjunto de **reglas basadas en el dominio** sobre las trayectorias:

   * Una trayectoria que inicia fuera de la estaci√≥n y luego ingresa al pol√≠gono de la estaci√≥n, cumpliendo un tiempo m√≠nimo fuera, se clasifica como evasi√≥n.
   * Una trayectoria que desaparece cerca del pol√≠gono mientras se dirige hacia la estaci√≥n tambi√©n se considera evasi√≥n, capturando casos de oclusi√≥n o saltos.
   * Se incorporan mecanismos para evitar dobles conteos y reducir falsos positivos/negativos.

5. **Conteo de eventos de evasi√≥n**
   Cada trayectoria puede generar como m√°ximo un evento de evasi√≥n, permitiendo estimar de forma confiable la cantidad de ingresos ilegales por clip.

Este enfoque h√≠brido combina la robustez del deep learning con la interpretabilidad de reglas expl√≠citas, lo que resulta adecuado para escenarios reales de videovigilancia.

<img width="1147" height="681" alt="image" src="https://github.com/user-attachments/assets/a1c4ddc8-c528-46e9-8cbc-d9667c34ea4e" />

---

## üìä Dataset y evaluaci√≥n

* **1.800 clips de video reales** capturados en estaciones de TransMilenio

  * 1.200 clips con al menos un evento de evasi√≥n
  * 600 clips sin evasi√≥n
* Escenarios diversos: horas pico, alta densidad de personas, oclusiones, distintas orientaciones de estaci√≥n
* Cada video tiene una duraci√≥n entre 20-24 segundos

El m√©todo fue evaluado mediante una **exploraci√≥n sistem√°tica de par√°metros (grid search)** sobre 300 videos representativos aplicando 40 configuraciones diferentes, variando:

* Modelos y umbrales de detecci√≥n
* Algoritmos de tracking
* Par√°metros espaciales y temporales del an√°lisis de trayectorias

La m√©trica principal de evaluaci√≥n fue el **F1-score**, ya que permite balancear precisi√≥n (reducci√≥n de falsas alarmas) y recall (detecci√≥n de eventos reales), aspecto cr√≠tico en este contexto.

A continuaci√≥n se presenta el ranking de las 20 mejores configuraciones
<img width="4727" height="2392" alt="image" src="https://github.com/user-attachments/assets/18dcd688-b9a7-49a7-94c8-51851d04de3f" />

La mejor configuraci√≥n encontrada consta de los siguientes par√°metros:
```python
config = {
    "id": 30,
    "models": {
        "person": {
            "model": "yolo11m.pt",
            "conf": 0.35,
            "iou": 0.4,
            "tracker": "botsort.yaml",
            "imgsz": 1280,
        },
        "station": "stationv1.pt",
    },
    "PROXIMITY_THRESHOLD": 50,
    "MIN_TIME_OUTSIDE": 1,
}
```

Esta configuraci√≥n se toma como la configuraci√≥n por defecto en la demostraci√≥n de este repositorio.

## Validaci√≥n final

Luego de tener la mejor configuraci√≥n para los par√°metros del m√©todo, se realiz√≥ la validaci√≥n con 1500 videos, donde 1000 videos presentaban casos de evasi√≥n y 500 no.
A continuaci√≥n se presentan dos matrices, la primera basada en los conteos exactos y la segunda basada en eventos de evasi√≥n, esta segunda matriz se calcula con las diferencias de conteos predichos y reales en cada video.

<img width="772" height="364" alt="image" src="https://github.com/user-attachments/assets/dc4c7514-4824-468a-99c9-03e283fddb2e" />

|  Precision |     Recall |   F1-Score |   Accuracy | MAE       |
| ---------: | ---------: | ---------: | ---------: | --------: |
| **0.9270** | **0.7828** | **0.8488** | **0.7866** | **0.341** |

Con estos resultados se concluy√≥ que:
* El alto valor de precisi√≥n indica una baja tasa de falsas alarmas en la detecci√≥n de evasi√≥n.
* El recall refleja una buena capacidad del m√©todo para identificar eventos reales de evasi√≥n, incluso en escenarios congestionados.
* El F1-Score evidencia un balance adecuado entre precisi√≥n y recall.
* El MAE muestra que el error promedio en el conteo de evasiones por video es reducido.
* El conteo exacto indica que el m√©todo logra estimar correctamente el n√∫mero de evasiones en un 75% de los casos.
* El m√©todo tiene m√©tricas destacables teniendo en cuenta la alta complejidad que presentan los videos.

---

## üé• Ejemplos

A continuaci√≥n se muestran ejemplos de videos procesados por el m√©todo, donde se visualizan las personas detectadas, sus trayectorias y los eventos de evasi√≥n identificados.

<details>
  
  <summary><strong>Ejemplos complejos de evasi√≥n üìΩÔ∏è</strong></summary>
  
  <br>
  
  https://github.com/user-attachments/assets/235bc1b1-b455-47f2-ad22-f318bc1217b2

  https://github.com/user-attachments/assets/55f725c8-4d94-4826-83ef-925a5a80ec28

</details>

<details>
  
  <summary><strong>Ejemplos regulares de evasi√≥n üìΩÔ∏è</strong></summary>
  
  <br>
  
  https://github.com/user-attachments/assets/7c1b3d60-0d6b-4e25-a0e5-2dd6ddb5bdca

  https://github.com/user-attachments/assets/64bcc0de-08ca-4937-a94d-634037ca623d

</details>


<details>
  
  <summary><strong>Ejemplos de no evasi√≥n üìΩÔ∏è</strong></summary>
  
  <br>
  
  https://github.com/user-attachments/assets/e008d617-310e-4815-bdd4-283896ace219

  https://github.com/user-attachments/assets/2b147f02-0e1c-4a0f-95d1-1536de8562bc
  
  https://github.com/user-attachments/assets/3b1104c4-5b56-4077-9309-c3bc351333cd

</details>


<details>
  
  <summary><strong>Ejemplos de casos mixtos üìΩÔ∏è</strong></summary>
  
  <br>
  
  https://github.com/user-attachments/assets/1afe256b-a6d7-4dc2-8a1e-3a656b08fba7

</details>

---

## üß™ Uso del m√©todo

* En este reopositorio se encuentra un [`ejemplo de implementaci√≥n `](https://github.com/FtxDJuan1214/deteccion-de-evasion-en-sistemas-BRT/blob/main/ejemplo%20de%20implementaci%C3%B3n/implementation.py)
 este se complementa con los videos de la [`carpeta de ejemplos `](https://github.com/FtxDJuan1214/deteccion-de-evasion-en-sistemas-BRT/tree/main/videos%20ejemplos) que serviran para hacer multiples pruebas localmente.

---

## ‚ú® Aportes principales

* Propuesta de un **m√©todo autom√°tico y explicable** para la detecci√≥n de evasi√≥n por puerta de vag√≥n
* Integraci√≥n de **segmentaci√≥n de la estaci√≥n, detecci√≥n de personas, tracking multiobjeto y an√°lisis de trayectorias**
* Validaci√≥n experimental extensiva con datos reales de operaci√≥n
* Pipeline reproducible y adaptable a otros sistemas BRT

---

## üìå Consideraciones

* Este repositorio tiene un **prop√≥sito acad√©mico y de investigaci√≥n**.
* No representa un sistema de vigilancia en producci√≥n.
* Los videos se comparten √∫nicamente con fines demostrativos y cient√≠ficos.

---

## üë§ Autor

**Juan Camilo Hern√°ndez Ortiz**

Maestr√≠a en Ingenier√≠a ‚Äì Ingenier√≠a de Sistemas y Computaci√≥n

Universidad Nacional de Colombia

2025

---

## üìÑ Licencia

Este proyecto se comparte para uso acad√©mico y de investigaci√≥n. Revisa el archivo [`LICENSE`](https://github.com/FtxDJuan1214/deteccion-de-evasion-en-sistemas-BRT/blob/main/LICENSE) para m√°s detalles.
